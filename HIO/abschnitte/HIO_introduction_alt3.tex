\section{Dynamic Systems}
Whether you work in the fields of biology, chemistry or physics, or you deal with problems of applied 
sciences, the system you want to control, construct or investigate will probably be governed by underlying 
principles and laws of nature. These principles, either fundamental empirical, are usually formulated in means 
of \textit{differential equations}. For example the famous Lotka-Volterra equations
\begin{align}
	\frac{\td}{\td t}N_1 &= \alpha_1 N_1 - \beta_2 N_1 N_2 \\
	\frac{\td}{\td t}N_2 &= \beta_1 N_1N_2 -\alpha_2 N_2 \quad ,
\end{align} 
that describe evolution of the number of preys $N_1$ and the number of predators $N_2$ in time, with some 
parameters that encode properties of the animals and the environment. Also the wave equation
\begin{equation}
	\left(\frac{\td^2}{\td t^2} -\frac{\td^2}{\td x^2} -\frac{\td^2}{\td y^2} -\frac{\td^2}{\td z^2}\right)
	 \psi = 0 \quad , 
\end{equation}
that provides a mathematical equation for e.g. electromagnetic and also mechanical waves is a (partial) 
differential equation. An interesting class of differential equations is called \textit{first order autonomous 
ordinary differential equations}. This kind of differential equations describes the time evolution of a vector 
$x$, called \textit{state vector}, a numerical quantity that has the full information about the state of the 
considered system at each point in time. It takes the general form
\begin{equation}
	\frac{\td}{\td t} x = f(x,u) \label{eq:intro_systemeq}
\end{equation}
where $x$ is an possibly $n$-dimensional vector, and $u$ is a known 
external input called \textit{control}. The function $f$ encodes all the information about the system, that is 
all interactions within the system as well as the influence of the control. Therefore equation 
\eqref{eq:intro_systemeq} is called the \textit{system equation} and the system of interest is called a 
\textit{dynamic system}. You have already seen the Lotka-Volterra 
equations as an example of $2$-dimensional first order autonomous differential equation without external inputs. 

\paragraph*{Structural Error Estimation in Dynamical Systems}
It is the rule, rather than the exception, that we do not know the systems equation of a system we want 
to investigate. Most of the time we have a clue, though, how it could look like. This guess we will call the 
\textit{nominal model} $\tilde{f}$, and the expected evolution of the state vector $\tilde{x}$. Let us assume 
that there principally exists a true $f$ that governs the behaviour of the system, and for simplicity we ignore external inputs. Then 
\begin{equation}
	w := f(x) - \tilde{f}(x)
\end{equation} 
is a quantitative, time-resolved measure, whether the nominal and the true model coincide, or not. We call 
this \textit{systematic model error} or simply \textit{hidden input}. \\

One main problem in the sciences of dynamic systems is, that we have only limited knowledge about the state $x$. 
E.g. you can measure weather conditions, temperature, wind speed, the amount of rain etc. in a specific region 
at a specific time, but mathematically you would have to get all these data everywhere at all times, to 
predict the weather of the next day. This leads to the concept of the \textit{observation function} $h$ that maps 
the state $x$ of a dynamic system to the measured quantities $y:=h(x)$, called \textit{observables}. Consequently 
this makes the determination of the quantity $w$ a nontrivial task.  \\

Let us collect the possible errors, we have to keep in mind when working with dynamic systems
\begin{itemize}
	\item We work with a nominal $\tilde{f}$, that differs from the true $f$.
	\item In addition to the deterministic $f$ there could be random processes, $\epsilon$ that influence 
	the states.
	\item The observation function could be wrong, namely  \text{systematic measurement errors}, and could have 
	additional random terms, called \text{measurement noise}.
\end{itemize}

Assume we have data $y^\text{obs}$ and simulated data $\hat{x}$ on the basis of $\tilde{f}+\hat{w}$. If 
we could minimize
\begin{equation}
	||y^\text{obs} - h(\hat{x})||^2
\end{equation}
with respect to a guessed hidden input $\hat{w}$, is this optimal hidden input $\hat{w}^\text{min}$ the 
information we need to learn the true system $f$ on basis of the data $y^\text{obs}$? \\

This question is the initial point of the 
SEED-project. \\

The last months showed that for a variety of low and medium dimensional systems, the \textit{Dynamic Elastic Net} 
with its two approaches, the \textsf{Greedy-Approach Gradient-Method} and the \textsf{Bayesian DEN}, showed 
that they are able to reconstruct structural errors in dynamic systems to a high precision and therefore may 
provide be a fruitful tool improve the mathematical models of dynamic systems.

\paragraph*{Hidden Input Observability}
The questions you directly derive from the Dynamic Elastic Net approach are:
\begin{itemize}
	\item Does a optimal hidden input $w$ exist?
	\item Can we give an algorithm to calculate this optimal hidden input?
	\item Is the solution unique?
	\item Is the procedure stable against measurement errors and numerical errors?
\end{itemize}

The framework for the determination of hidden inputs is given by the \textit{optimal control theory}, where in 
this case the hidden input is the control that shall be optimized for archive an optimal fit to the data, 
subject to the governing systems equations. Thus some ideas and algorithmic approaches from this field can 
be adapted. \\

As the result of the work so far, the \textsf{Greedy-Approach Gradient-Method} is provides fast and reliable
deterministic algorithm to compute hidden inputs by comparing data with a given nominal model. However there 
seem to exist types of dynamic systems, that give remarkably good results, where some dynamical systems seem to 
hide their hidden inputs very effectively. So the obvious questions is: What are the conditions, to guarantee 
uniqueness of the optimal hidden inputs? We call this property \textit{hidden input observability}. We will 
start with the investigation of linear systems and we will see, that it is possible to give sufficient and 
necessary conditions in means of the algebraic properties of the system as well as the graphical representation 
as a network graph. \\

As a starting point of the mathematical treatment consider a true general linear system
\begin{equation}
	\dot{x} = Ax + Bu \tab{,} y=Cx
\end{equation}
and a nominal guess
\begin{equation}
	\dot{\tilde{x}} = \tilde{A}\tilde{x} + Bu \tab{,} y=Cx \quad .
\end{equation}
At this point we assume that the external inputs $Bu$ and the observation function $x\mapsto Cx$ are known. Now 
imagine we add two different hidden inputs $w$ and $w'$ to the system such that the solution $\hat{x}$
\begin{equation}
	\dot{\hat{x}} = \tilde{A} \hat{x} + Bu + Dw \tab{,} \hat{y} = C\hat{x}
\end{equation} 
coincides with the observations, and analogous does $\hat{y}'=C\hat{x}'$, the solution for $w'$. Due to 
linearity we can subtract $\hat{y}'$ from $\hat{y}$ to get
\begin{equation}
	\dot{\delta x} = \tilde{A} \delta x + D \delta w \tab{,} \delta y = C \delta x \label{eq:intro_difference}
\end{equation}
where $\delta x=\hat{x}-\hat{x}'$ and analogous for $w$ and $y$. We deduce
\begin{equation*}
\begin{aligned}&
\text{A linear system is hidden input observable,}\\ &\quad 
\text{if the equations \eqref{eq:intro_difference} provide an injective.}
\end{aligned}
\end{equation*}
