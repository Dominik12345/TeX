\section{Hidden Input Observability}

We consider a mapping $L^2([0,T])^{\otimes m}\to L^2([0,T])^{\otimes p}$ defined by 
\begin{equation}
y(t) := C \int\limits_0^t \e^{A(t-\tau)} D w(\tau) \, \td \tau \label{eq:y}
\end{equation}
where $w:[0,T]\to \mathbb{R}^m$, $y:[0,T]\to \mathbb{R}^p$, $A\in\mathbb{R}^{n\times n}$, 
$D\in\mathbb{R}^{n\times m}$ and $C\in\mathbb{R}^{p\times n}$. \\

We assume that in an biological system the functions $w$ and $y$ are defined on 
a natural interval of time that covers $[0,T]$. This means that for a small $\epsilon$ the 
model could be extended to an interval $(0-\epsilon , T+\epsilon)$ and thus differentiation 
of $w$ and $y$ at $t=0$ and $t=T$ makes sense. To denote this idea without 
introducing $\epsilon$ we use the notation $[0^-,T^+]$.
\\

It is clear, that if $D$ is not injective, we can find nonzero $w\in\kernel{D}$ that 
produce zero output. For this, we will only consider injective $D$. Furthermore if 
$C$ is not surjective, we can reduce the number of observables since $(p-\rank{C})$ 
observables are redundant. Thus we will only consider surjective $C$. Then also 
$p \leq n$ and  $p \leq n$.\\

We firstly rewrite the problem by expanding \eqref{eq:y}, 
\begin{equation}
y(t) = \sum\limits_{k=0}^\infty CA^kD \int\limits_0^t \frac{(t-\tau)^k}{k!} w(\tau) \, \td 
\tau \quad .
\end{equation}
Writing $(CA^kD)_{.\mu}$ means the $\mu$-th column and $w_\mu$ the $\mu$-th component
%. We 
%get 
%\begin{equation}
%y(t) = \sum\limits_{k=0}^\infty \sum\limits_{\mu=1}^m \int\limits_0^t \frac{(t-\tau)^k}{k!}
%w_\mu(\tau) \, \td \tau (CA^kD)_{.\mu} 
%\end{equation} 
and if we only consider the $\nu$-th component of $y$ we get 
\begin{equation}
y_\nu(t) = \sum\limits_{k=0}^\infty \sum\limits_{\mu=1}^m \int\limits_0^t 
\frac{(t-\tau)^k}{k!} w_\mu(\tau) \, \td \tau (CA^kD)_{\nu\mu} \quad .
\end{equation}
We introduce the coefficients $c_k^{\mu\nu} : = (C A^k D)_{\nu\mu}$ to get
\begin{equation}
y_\nu(t) = \sum\limits_{\mu=1}^m \sum\limits_{k=0}^\infty  c_k^{\mu\nu}  \int\limits_0^t 
\frac{(t-\tau)^k}{k!} w_\mu(\tau) \,\td\tau
\quad \forall \nu = 1,2,\ldots , p
 \quad . \label{eq:y_operator}
\end{equation}
Here, it is legit to commute the sums, since the infinite sum over $k$ is absolutely 
convergent.\\

\subsection{Basic Properties}
It is now convenient to introduce some operators.
\begin{definition}{}{}
	Let $v\in L^2$ be a function and $(c_k)_{k\in\mathbb{N}_0}$ a real-valued sequence. 
	For the sake of readability we write 
	$c=(c_k)_{k\in\mathbb{N}_0}$ for sequences. 
	\begin{enumerate}
	\item $\phi_k[v](t):= \int_0^t \frac{(t-\tau)^k}{k!} v(\tau) \, \td \tau $
	\item $\Phi_c[v] : = \sum_{k=0}^\infty c_k \phi_k[v]$
	\end{enumerate}
	We always exclude the sequence $c_k=0\forall k$, since 
	this obviously produces the operator that maps everything to the zero function and 
	thus cannot be injective.
\end{definition}
We rewrite \eqref{eq:y_operator} as
\begin{equation}
y_\nu(t) = \sum\limits_{\mu=1}^m \Phi_{c^{\mu\nu}}[w_\mu](t) 
\quad \forall \nu =1,2,\ldots , p   \label{eq:y_Phi}
\end{equation}
and discuss some properties.

\begin{lemma}{Properties of $\phi_k$}{}
	\begin{enumerate}
	\item $\phi_k[v](0) = 0$
	\item $\frac{\td}{\td t}\phi_0[v](t)=v(t)$ and
	$\frac{\td}{\td t}\phi_k[v](t) = \phi_{k-1}[v](t)$
%	\item $\phi_k$ is injective, i.e. $\phi_k[v]\equiv 0 \Rightarrow v\equiv 0$
	\end{enumerate}
\end{lemma}
\begin{proof}
	The first property is trivial.\\
	Computing $\phi_k[v](t+\Delta t)$ yields
	\begin{equation}
	\phi_k[v](t+\Delta t) = \int\limits_0^t \frac{(t-\tau + \Delta t)^k}{k!} v(\tau) 
	\, \td \tau + \int\limits_t^{t+\Delta t}   \frac{(t-\tau + \Delta t)^k}{k!} v(\tau) 
	\, \td \tau 
	\end{equation}
	and using $(t+\Delta t)^k =t^k + k t^{k-1} \Delta t + \mathcal{O}(\Delta t^2)$ for 
	$k>0$ and $(t+\Delta t)^0 = 1$ and a small $\Delta t$ leads to 
	\begin{equation}
	\phi_k[v](t+\Delta t) \simeq \int\limits_0^t \frac{(t-\tau)^k}{k!} v(t) \, \td \tau 
	+ \Delta t \int\limits_0^t \frac{(t-\tau)^{k-1}}{(k-1)!} v(t) \, \td \tau
	\end{equation}
	if $k>0$ and to 
	\begin{equation}
	\int\limits_0^t \frac{(t-\tau)^0}{k!} v(t) \, \td \tau +  \Delta t v(t)
	\end{equation}
	if $k=0$. Comparing this with the definitions of the operators we get \\
	$\phi_k[v](t+\Delta t) \simeq \phi_k(t) + \Delta t\phi_{k-1}[v](t)$ and 
	$\phi_0[v](t+\Delta t) \simeq \phi_0[v](t) + \Delta t v(t)$. Taking the limit 
	$\Delta t\to 0$ ends the proof of the derivation rules. \\
%	Setting $\phi_0[v]\equiv 0$ and taking the derivative $v\equiv 0$ shows, that 
%	$\phi_0$ is injective.
%	Assuming $\phi_{k-1}$ is injective, we set $\phi_k[v]\equiv 0$. Then also the 
%	derivative \\
%	$\frac{\td }{\td t}\phi_k[v]=\phi_{k-1}[v]\equiv 0$ which implies $v\equiv 0$ since 
%	$\phi_{k-1}$ is injective. This completes the induction.
\end{proof}

%\begin{lemma}{Unit Sequence}{}
%	If $c=(1,1,\ldots)$ or any multiple of this, then $\Phi_c$ is injective.
%\end{lemma}
%\begin{proof}
%	Set $\Phi_c[v]=\sum_{k=0}^\infty \phi_k[v] \equiv 0$. Derivation with respect to 
%	$t$ yields \\$v + \sum_{k=1}^\infty \phi_{k-1}[v]\equiv 0$ and shifting the index 
%	$k\to k-1$ shows\\ $v + \sum_{k=0}^\infty \phi_k[v]=v+\Phi_c[v]=v\equiv 0$.
%\end{proof}
\subsection{SISO-System}
We start with a \textit{Single Input Single Output (SISO)}-System. That means
\eqref{eq:y_Phi} simplifies to
\begin{equation}
	y(t) = \Phi_c[v](t)
\end{equation}
with a real-valued $y$ and $v$ and a scalar $c_k=(CA^kD)$.
\begin{proposition}{}{}
	Let $v$ be an integrable function on $[0^-,T^+]$ and let \\
	$\Phi_c[v]\equiv 0$. Then
	\begin{equation}
	\sum\limits_{l=0}^q c_l v^{(q-l)}(0)=0 \quad \forall q \in \mathbb{N}_0 \tag{$\star$}
	\label{eq:prop1}
	\end{equation}
	where $v^{(q)}(0)$ denotes the $q$-th derivative of $v$ at $t=0$.
\end{proposition}
\begin{proof}
	Consider
	\begin{equation}
	\Phi_c[v] = c_0 \phi_0[v] + c_1 \phi_1[v] + \ldots + c_{q-1}\phi_{q-1}[v] + 
	c_q \phi_q[v] + c_{q+1} \phi_{q+1}[v] + \ldots 
	\end{equation}
	and the $(q+1)$-th derivative
	\begin{equation}
	\left( \frac{\td}{\td t} \right)^{q+1}\Phi_c[v] = c_0 v^{(q)} + c_1 v^{(q-1)} + 
	\ldots 	+ c_{q-1} v^{(1)} + c_q v^{(0)} + c_{q+1} \phi_0[v] + \ldots
	\end{equation}
	for short
	\begin{equation}
	\left( \frac{\td}{\td t} \right)^{q+1}\Phi_c[v] = \sum\limits_{l=0}^q c_l v^{(q-l)} 
	+\sum\limits_{l=0}^\infty c_{q+1+l} \phi_{l}[v] \quad . 
	\end{equation}
	Evaluating the latter expression at $t=0$ completes the proof.
\end{proof}

To illustrate the idea of the following lemma and theorem we write down some 
instances of \eqref{eq:prop1}: 
\begin{align*}
&q = 0& &c_0 v^{(0)} \\
&q = 1& &c_0 v^{(1)} &&+&&c_1 v^{(0)} \\
&q = 2& &c_0 v^{(2)} &&+&&c_1 v^{(1)} &&+&&c_2 v^{(0)} \\
&q = 3& &c_0 v^{(3)} &&+&&c_1 v^{(2)} &&+&&c_2 v^{(1)} && +&&c_3 v^{(0)}\\
&q = 4& &c_0 v^{(4)} &&+&&c_1 v^{(3)} &&+&&c_2 v^{(2)} && +&&c_3 v^{(1)} &&+&& c_4 
v^{(0)} \\ 
&\,\, \vdots && && \ddots && &&\ddots && &&\ddots && &&\ddots && &&\ddots 
\end{align*}
For a better readability each $v^{(q)}$ is understood to be evaluated at $t=0$. The 
structure of this triangle remains the same if $c_0=0$, i.e. the first column vanishes, 
and if $v^{(0)}=0$, i.e. the diagonal at the top vanishes. 

\begin{lemma}{Induction Step}{}
	Assume proposition 1 holds and let $c_K$ be the first nonzero coefficient. 
	If there is a $r\in\mathbb{N}_0$ with $v^{(0)}(0)=
	v^{(1)}(0)=\ldots= v^{(r-1)}(0)=0$ then $v^{(r)}(0)=0$. 
\end{lemma}
\begin{proof}
	Using \eqref{eq:prop1} with $q = r+K$ yields 
	\begin{equation}
	\sum\limits_{l=0}^{r+K} c_l v^{(r+K-l)}(0) = c_K v^{(r)}(0) = 0
	\end{equation}
	since all other terms of the sum vanish due to $c_l=0$ or $v^{(l)}=0$. This shows 
	that also $v^{(r)}(0)=0$.
\end{proof}

\begin{theorem}{}{}
	Let $v\in L^2([0,T])\cap C^\infty(0^-,0^+)$ and $c$ a sequence. Then
	\begin{equation}
	\Phi_c[v] \equiv 0\quad  \Rightarrow\quad v^{(q)}(0) = 0
	 \quad \forall q\in\mathbb{N}_0 \quad .
	\end{equation}
\end{theorem}
\begin{proof}
	Let $c_K$ be the first nonzero coefficient. Using \eqref{eq:prop1} with $q=K$ yields 
	\begin{equation}
	c_K v^{(0)} = 0 
	\end{equation}
	which shows that $v^{(0)}=0$. Using lemma 2 completes the inductive proof.
\end{proof}

\begin{corollary}{}{}
	If $v$ can be represented by its Taylor-expansion, then $\Phi_c[v]\equiv 0$ implies 
	$v\equiv 0$.\\
	
	If there is a disjoint union $[0^-,T^+] = I_1\dot{\cap} I_2 \dot{\cap}\ldots$ such 
	that 
	$v$ has a valid Taylor-expansion on each interval $I_j=(t_{j-1}^-,t_j^+)$, we can argue 
	that $v\equiv 0$ on $I_1$. This leads to $\phi_k[v](t_1)=0$ which allows us to get 
	a modification of \eqref{eq:prop1}, written out
	\begin{equation}
	\sum\limits_{l=0}^q c_l v^{(q-l)}(t_1) = 0 \quad \forall q \in \mathbb{N}_0 \quad .
	\end{equation}
	Formally this can again be handled as an inductive proof to show, that $v$ must 
	vanish on each interval.\\
	
	A SISO-system is HIO if and only if there is an $k\in\mathbb{N}_0$  
	$CA^kD \neq 0$. 
\end{corollary}

\subsection{MIMO-Systems}
As equation \eqref{eq:y_Phi} shows, we usually do not have a simple $y(t)=\Phi_c[v](t)$ 
relation but a sum with different sequences $c^{\mu\nu}$ and functions $w_\mu$. Since 
summation and differentiation are linear operations, we directly get the following 
extension of proposition 1.
\begin{proposition}{}{}
	Let $w_\mu$ integrable on $[0^-,T^+]$ for $\mu=1,2,\ldots , m$ and let 
	$c^{\mu\nu}$ be sequences. For each $\nu=1,2,\ldots, p$
	\begin{equation}
	\sum\limits_{\mu=1}^m \Phi_{c^{\mu\nu}}[w_\mu] \equiv 0 \quad \Rightarrow \quad 
	\sum\limits_{\mu=1}^m\sum\limits_{l=0}^q c^{\mu\nu}_l w_\mu^{(q-l)}(0) = 0 \quad 
	\forall q \in \mathbb{N}_0 \tag{$\star\star$} \label{eq:prop2}
 	\end{equation}
\end{proposition}
\begin{proof}
	The proof works analogous to that of proposition 1.
\end{proof}

Whereas theorem 1 holds for any sequence $c$ and function $v$, proposition 2 allows 
cancellation of different functions $w_\mu$. We shortly demonstrate, that a fully 
observed system will always be hidden input observable.
Considering a fully observed system with possible hidden inputs on each state, i.e. 
$C=D=\mathbb{1}$ and $p=n=m$, we directly get $c_0^{\mu\nu}=\delta_{\mu\nu}$. 
Inserting this into 
\eqref{eq:prop2} with $q=0$ yields 
\begin{equation}
w_\nu^{(0)} = 0 \tab{for} \nu = 1,2,\ldots , n
\end{equation}
Following the idea of lemma 2 we proceed with an induction step to get
\begin{equation}
w_\nu^{(q)} = 0 \quad \forall q\in\mathbb{N}_0 \tab{for} \nu = 1,2,\ldots , n \quad .
\end{equation}
As argued in corollary 1, if we assume that each $w_\mu$ can be represented by a 
Taylor series, we know, that this system is hidden input observable. \\

\subsubsection{Directly Observed Hidden Inputs}
To generalize the idea of an fully observed system we find the following lemma in analogy 
to lemma 2.
\begin{lemma}{Induction Step}{}
	Assume proposition 2 holds and assume for an integer $K$ 
	that $CD=CAD=\ldots = CA^{K-1}D = 0$ and $CA^KD$ has rank $m$. If there is an $r\in
	\mathbb{N}$ such that $w_\mu^{(0)}(0)=\ldots =w_\mu^{(r-1)}(0)=0$ for all $\mu =
	1,2,\ldots , m$, then $w_\mu^{(r)}(0)=0$ for all $\mu$.
\end{lemma}
\begin{proof}
	Using \eqref{eq:prop2} with $q=r+K$ yields
	\begin{equation}
	\sum\limits_{\mu=1}^m c_K^{\mu\nu} w_\mu^{(r)}(0) = 0
	\end{equation}
	which is by definition of $c_K^{\mu\nu}$ equivalent to the linear equation 
	\begin{equation}
	CA^K D w^{(r)} (0) = 0
	\end{equation}
	where $w^{(r)}(0)$ is the vector $(w_1^{(r)}(0),\ldots,w_m^{(r)}(0))$. If and only if 
	$\rank{CA^KD} = m$ this implies $w^{(r)}(0)=0\in\mathbb{R}^m$.
\end{proof}

\begin{theorem}{Directly Observed Hidden Inputs}{}
	Let $w\in L^2([0,T])^{\otimes m}\cap C^\infty(0^-,0^+)^{\otimes m}$ and $(A,C,D)$ the 
	matrices of 
	\eqref{eq:y} and assume that $CA^KD$ is the first nonvanishing coefficient matrix.\\ If 
	$\rank{CA^KD} = m$, then
	\begin{equation}
	y \equiv 0 \quad \Rightarrow \quad w_\mu^{(q)}(0) = 0 \quad \forall q\in\mathbb{N}_0
	\quad .
\end{equation}	 
\end{theorem}
\begin{proof}
	Due to the assumptions we can use proposition 2. Equation \eqref{eq:prop2} with 
	$q = K$ yields
	\begin{equation}
	\sum\limits_{\mu=1}^m c_K^{\mu\nu} w_\mu^{(0)}(0) = 
	\sum\limits_{\mu=1}^m \left( CA^KD\right)_{\nu\mu} w_\mu^{(0)}(0)= 0 \quad \forall 
	\nu \in \{1,2,\ldots, p\}
	\end{equation}
	which implies $w_\mu^{(0)}(0)=0\forall \mu$, since $(CA^KD):\mathbb{R}^m
	\to\mathbb{R}^p$ is injective. This allows us to use lemma 3 as an induction step to 
	complete the proof.
\end{proof}

\subsubsection{Indirectly Observed Hidden Inputs}
In the following example you can see a composition of two HIO systems. Though it should 
again be HIO, we cannot prove this by using theorem 2.
\begin{example}{}{}
	Consider the obviously HIO system
	\begin{equation}
	A = 0 \tab{,} D = 1 \tab{,} C = 1 \quad .
	\end{equation}
	Furthermore consider the system
	\begin{equation}
	A = \begin{pmatrix}
	0 & 0 \\ 1 & 0
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	1 \\ 0
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	0 & 1
	\end{pmatrix}
	\end{equation}
 	which yields $CD = 0$ and $CAD=1$ and therefore is also HIO.
 	If we simply write these two systems into one system
	\begin{equation}
	A = \begin{pmatrix}
	0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 1 & 0
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	1  & 0\\ 0 & 1 \\ 0 & 0
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	1&0&0\\0 &0 & 1
	\end{pmatrix}
	\end{equation}
 	we get $\rank{CD}=1$ which means we cannot apply theorem 2 to prove HIO.
\end{example}

To get an extension of theorem 2 we need a new construct. 
\begin{definition}{}{}
	Consider $CA^kD$ and define an index set $\mathcal{I}^k$ for each $k\in\mathbb{N}_0$
	by 
	\begin{equation}
	\mu \in\{1,2,\ldots,m\} \tab{is element of} \mathcal{I}^k \quad \Leftrightarrow 
	\quad  (CA^kD)_{. \mu} \neq 0  \quad . 
\end{equation}		
	Here $(CA^kD)_{.i}$ denotes the $i$-th column. \\
	
	For a better readability $\mathcal{R}^k:= 
	\mathcal{I}^k\backslash (\mathcal{I}^{k-1}\cup \ldots \cup \mathcal{I}^0)$.\\

	The \textit{reduced matrices} $(CA^kD)^*$ are defined by
	\begin{equation}
	(CD)^* = \left[ CD_{.\mu} \right]_{\mu \in \mathcal{I}^0}
	\end{equation}
	and 
	\begin{equation}
	(CA^kD)^* = \left[ (CA^{k-1}D)^* \left[ CA^kD_{.\mu}  \right]_{\mu\in\mathcal{R}^k} 
	\right]	 \quad .
	\end{equation}
	The square brackets mean the composition of columns to a new matrix.
\end{definition}

\begin{example}{}{}
	Let us again consider the latter example.
	\begin{equation}
	CD = \begin{pmatrix}
	1 & 0 \\ 0 & 0
	\end{pmatrix}
	\tab{,} CAD = \begin{pmatrix}
	0 & 0 \\ 0 & 1
	\end{pmatrix} 
	\end{equation}
	We find $\mathcal{I}^0=\{1\}$ and $\mathcal{I}^1 =\{2\}$. The reduced matrices are
	\begin{equation}
	(CD)^* = \begin{pmatrix}
	1 \\ 0
	\end{pmatrix}
	\tab{,} 
	(CAD)^* = \begin{pmatrix}
	1 & 0 \\ 0 & 1
	\end{pmatrix}
	\end{equation}
	The first matrix contains only the nonzero columns of $CD$.
	The second matrix is the composition of $(CD)^*$ and the columns of $(CAD)$ with index 
	in $\mathcal{I}^1\backslash\mathcal{I}^0 =\{2\}$. In this example it is the composition 
	of the first column of $CD$ and the second column of $CAD$. \\
	We can see that both reduced matrices have full column rank and that the reduced 
	matrix of the highest power, $(CAD)^*$, has rank $m$. 
\end{example}

Using this construct we can generalize theorem 2.
\begin{theorem}{Indirectly Observed Hidden Inputs}{}
	Let $w:[0^-,T^+]\to \mathbb{R}^m$ be element of $L^2([0,T])^{\otimes m}\cap C^\infty 
	(0^-,0^+)^{\otimes m}$ and let $(A,C,D)$ be the matrices of a linear dynamic system 
	\eqref{eq:y}. \\
	If each reduced matrix $(CA^kD)^*$ is injective, i.e. has full column rank, and if 
	there is an integer $K$ such that $(CA^KD)^*$ has rank $m$, then
	\begin{equation}
	y\equiv 0 \quad \Rightarrow \quad w_\mu^{(q)} (0) = 0 \quad \forall q \in \mathbb{N}_0 
	\quad .
	\end{equation}
\end{theorem}
\begin{proof}
	Once more we prove by induction. Writing $w_\mu^{(q)}$ always means evaluated 
	at $t=0$. Let us set $y\equiv 0$.
	\begin{enumerate}
	\item	Proposition 2 with $q=0$ yields 
			\begin{equation}
			\sum\limits_{\mu=1}^m c_0^{\mu \nu} w_\mu^{(0)} = 0  \,\, \forall \nu 
			\tab{which implies}
			 \sum\limits_{\mu=1}^m w_\mu^{(0)} CD_{.\mu}  = 0 \quad .
			\end{equation}
			By definition of $\mathcal{I}^0$ we get
			\begin{equation}
			\sum\limits_{\mu\in\mathcal{I}^0} w_\mu^{(0)} (CD)_{.\mu} = 0 \quad .
			\end{equation}
			Since this is a linear combination of the columns of an injective matrix
			$(CD)^*$ we get
			\begin{equation}
			w_\mu^{(0)} = 0 \quad \forall \mu \in \mathcal{I}^0 \quad .
			\end{equation}
	\item	Before we do the induction step, let us use proposition 2 with $q=1$ to get
			\begin{equation}
			\sum\limits_{\mu \in \mathcal{I}^0} c_0^{\mu\nu} w_\mu^{(1)} + 
			\sum\limits_{\mu\in\mathcal{R}^1} c_1^{\mu\nu} w_\mu^{(0)} = 0 \quad \forall
			\nu \quad .
			\end{equation}
			Again written as a vector equation this is equivalent to
			\begin{equation}
			\sum\limits_{\mu \in \mathcal{I}^0} w_\mu^{(1)} (CD)_{.\mu} + 
			\sum\limits_{\mu\in\mathcal{R}^1}  w_\mu^{(0)} (CAD)_{.\mu} = 0  \quad .
			\end{equation}
			This again is a linear combination of columns of $(CAD)^*$. Since $(CAD)^*$ is 
			injective we get
			\begin{equation}
			w_\mu^{(0)} = 0 \quad \forall \mu \in \mathcal{I}^0\cup \mathcal{R}^1 
			\tab{and} w_\mu^{(1)} = 0 \quad \forall\mu \in \mathcal{I}^0	\quad .
			\end{equation}
			We note that $\mathcal{R}^i \cup \mathcal{I}^{i-1}\cup \ldots\cup 
			\mathcal{I}^0$ is 
			equal to $\mathcal{I}^i \cup \mathcal{I}^{i-1}\cup \ldots \cup \mathcal{I}^0$.
	\item Following the idea of step 2 we do the induction step:\\ Assume we have found an 
			integer $r$ such that
			\begin{align*}
			w_\mu^{(0)} &= 0 \,\,
			\forall \mu \in \bigcup\limits_{\rho =0}^r \mathcal{I}^\rho  \\
			w_\mu^{(1)} &= 0 \, \,
			\forall \mu \in \bigcup\limits_{\rho =0}^{r-1} \mathcal{I}^\rho 
			\\	
			&\vdots
			 \\
			w_\mu^{(r)} & = 0 \, \,
			\forall \mu \in  \mathcal{I}^0
			\end{align*}
			then use proposition 2 with $q=r+1$ to get for all $\nu$
			\begin{equation}
			\sum\limits_{\mu=1}^m c_0^{\mu\nu} w_\mu^{(r+1)} + 
			\sum\limits_{\mu \not\in\mathcal{I}^0} c_1^{\mu\nu} w_\mu^{(r)} + 
			\ldots + 
			\sum\limits_{\mu\not\in\mathcal{I}^0\cup\ldots\cup \mathcal{I}^{r}} 
			c_{r+1}^{\mu\nu} w_\mu^{(0)} = 0		\quad .	 
			\end{equation}
			As a vector equation we get
			\begin{equation}
			\sum\limits_{\mu=1}^m w_\mu^{(r+1)} (CD)_{.\mu} + 
			\sum\limits_{\mu\not\in\mathcal{I}^0} w_\mu^{(r)} (CAD)_{.\mu}+ 
			\ldots + 
			\sum\limits_{\mu\not\in\mathcal{I}^0\cup\ldots\cup \mathcal{I}^{r}} 
			w_\mu^{(0)} (CA^{r+1}D)_{.\mu} = 0		\quad .	 
			\end{equation}						
			We easily see that the combination $\mu\in\mathcal{I}^{\rho+1}$ and $\mu\not\in 
			\mathcal{I}^\rho\cup\ldots\cup \mathcal{I}^0$ is the same as $\mu\in
			\mathcal{R}^{q+1}$. Using the knowledge of zero columns we get
			\begin{equation}
			\sum\limits_{\mu\in\mathcal{I}^0}^m w_\mu^{(r+1)} (CD)_{.\mu} + 
			\sum\limits_{\mu\in\mathcal{R}^1} w_\mu^{(r)} (CAD)_{.\mu}+ 
			\ldots + 
			\sum\limits_{\mu\in\mathcal{R}^{r+1}} 
			w_\mu^{(0)} (CA^{r+1}D)_{.\mu} = 0		\quad .	 
			\end{equation}
			This is a linear combination of columns of $(CA^{r+1}D)^*$ which is injective. 
			Therefore
			\begin{align*}
			w_\mu^{(0)} &= 0 \,\,
			\forall \mu \in \bigcup\limits_{\rho =0}^{r+1} \mathcal{I}^\rho  \\
			w_\mu^{(1)} &= 0 \, \,
			\forall \mu \in \bigcup\limits_{\rho =0}^{r} \mathcal{I}^\rho 
			\\	
			&\vdots
			 \\
			w_\mu^{(r)} & = 0 \, \,
			\forall \mu \in  \bigcup\limits_{\rho =0}^{1} \mathcal{I}^\rho \\
			w_\mu^{(r+1)} & = 0 \, \,
			\forall \mu \in  \mathcal{I}^0 
			\end{align*}				
			This completes the induction.
	\item	Finally we show that the maximum $\bigcup_\rho \mathcal{I}^\rho = \{1,2,
			\ldots,m\}$ is always reached.  \\
			Assume there is an $m'<m$ such that $|\bigcup_\rho \mathcal{I}^\rho| = m'$ for 
			all $\rho \geq \rho_0$ but there is no $\rho$ such that $|\bigcup_\rho 
			\mathcal{I}^\rho| > m'$. Here $|.|$ denotes the number of elements. 
			\begin{enumerate}
			\item	By construction $(CD)^*$ has $|\mathcal{I}^0|$ columns.
			\item 	Then $(CAD)^*$ has exactly $|\mathcal{I}^0| + |\mathcal{R}^1|$ columns.
			\item  $(CA^{k}D)^*$ has exactly $|\mathcal{I}^0| + |\mathcal{R}^1|+\ldots 
			+ |\mathcal{R}^k|$ columns.
			\item 	There is an integer $K$ such that $(CA^KD)^*$ has column rank $m$. 
					This means $|\mathcal{R}^{K+1}|=0$.
			\end{enumerate}
			
	\end{enumerate}		

\end{proof}






We complete the MIMO-systems with the last corollary in analogy to corollary 1.
\begin{corollary}{}{}
	If there are a disjoint unions $[0^-,T^+]=I^\mu_1\dot{\cap} I_2^\mu\dot{\cap}\ldots$ 
	such that each $w_\mu$ can be represented by its Taylor-expansion on 
	each interval $I_j^\mu=((t_{j-1}^\mu)^- ,(t_j^\mu)^+)$ and if theorem 2 or theorem 3 
	holds, then the MIMO-system is HIO. \\
	
	To have any $CA^kD$ of rank $m$, we need $p\geq m$.
\end{corollary}

\subsubsection{Examples}

\begin{example}{}{}
	\begin{equation}
	A = \begin{pmatrix}
	1 & 0 \\ 1 & 1
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	1 \\ 0
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	1 & 0
	\end{pmatrix}
	\end{equation}
	A SISO-system and $CAD=1$ thus it is HIO.
\end{example}
\begin{example}{}{}
	\begin{equation}
	A = \begin{pmatrix}
	1 & 0 \\ 1 & 1
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	0 \\ 1
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	1 & 0
	\end{pmatrix}
	\end{equation}
	A SISO-system and $CA^kD=0$ for any integer $k$ thus it is not HIO.
\end{example}
\begin{example}{}{}
	\begin{equation}
	A = \begin{pmatrix}
	0 & 0  & 1\\ 1 & 0 & 0 \\ 0 & 1 & 0
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	1  & 0\\ 0 & 1 \\ 0 & 0
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	1 & 0 & 0 \\ 0 & 1 & 0
	\end{pmatrix}
	\end{equation}
	A MIMO-system and $CD$ is the $2\times 2$ identity matrix. Thus it is HIO.
\end{example}
