\section{Hidden Input Observability}

We consider a mapping $L^2([0,T])^{\otimes m}\to L^2([0,T])^{\otimes p}$ defined by 
\begin{equation}
y(t) := C \int\limits_0^t \e^{A(t-\tau)} D w(\tau) \, \td \tau \label{eq:y}
\end{equation}
where $w:[0,T]\to \mathbb{R}^m$, $y:[0,T]\to \mathbb{R}^p$, $A\in\mathbb{R}^{n\times n}$, 
$D\in\mathbb{R}^{n\times m}$ and $C\in\mathbb{R}^{p\times n}$. \\

We assume that in an biological system the functions $w$ and $y$ are defined on 
a natural interval of time that covers $[0,T]$. This means that for a small $\epsilon$ the 
model could be extended to an interval $(0-\epsilon , T+\epsilon)$ and thus differentiation 
of $w$ and $y$ at $t=0$ and $t=T$ makes sense. To denote this idea without 
introducing $\epsilon$ we use the notation $[0^-,T^+]$.
\\

It is clear, that if $D$ is not injective, we can find nonzero $w\in\kernel{D}$ that 
produce zero output. For this, we will only consider injective $D$. Furthermore if 
$C$ is not surjective, we can reduce the number of observables since $(p-\rank{C})$ 
observables are redundant. Thus we will only consider surjective $C$. Then also 
$p \leq n$ and  $p \leq n$.\\

We firstly rewrite the problem by expanding \eqref{eq:y}, 
\begin{equation}
y(t) = \sum\limits_{k=0}^\infty CA^kD \int\limits_0^t \frac{(t-\tau)^k}{k!} w(\tau) \, \td 
\tau \quad .
\end{equation}
Writing $(CA^kD)_{.\mu}$ means the $\mu$-th column and $w_\mu$ the $\mu$-th component
%. We 
%get 
%\begin{equation}
%y(t) = \sum\limits_{k=0}^\infty \sum\limits_{\mu=1}^m \int\limits_0^t \frac{(t-\tau)^k}{k!}
%w_\mu(\tau) \, \td \tau (CA^kD)_{.\mu} 
%\end{equation} 
and if we only consider the $\nu$-th component of $y$ we get 
\begin{equation}
y_\nu(t) = \sum\limits_{k=0}^\infty \sum\limits_{\mu=1}^m \int\limits_0^t 
\frac{(t-\tau)^k}{k!} w_\mu(\tau) \, \td \tau (CA^kD)_{\nu\mu} \quad .
\end{equation}
We introduce the coefficients $c_k^{\mu\nu} : = (C A^k D)_{\nu\mu}$ to get
\begin{equation}
y_\nu(t) = \sum\limits_{\mu=1}^m \sum\limits_{k=0}^\infty  c_k^{\mu\nu}  \int\limits_0^t 
\frac{(t-\tau)^k}{k!} w_\mu(\tau) \,\td\tau
\quad \forall \nu = 1,2,\ldots , p
 \quad . \label{eq:y_operator}
\end{equation}
Here, it is legit to commute the sums, since the infinite sum over $k$ is absolutely 
convergent.\\

\subsection{Basic Properties}
It is now convenient to introduce some operators.
\begin{definition}{}{}
	Let $v\in L^2$ be a function and $(c_k)_{k\in\mathbb{N}_0}$ a real-valued sequence. 
	For the sake of readability we write 
	$c=(c_k)_{k\in\mathbb{N}_0}$ for sequences. 
	\begin{enumerate}
	\item $\phi_k[v](t):= \int_0^t \frac{(t-\tau)^k}{k!} v(\tau) \, \td \tau $
	\item $\Phi_c[v] : = \sum_{k=0}^\infty c_k \phi_k[v]$
	\end{enumerate}
	We always exclude the sequence $c_k=0\forall k$, since 
	this obviously produces the operator that maps everything to the zero function and 
	thus cannot be injective.
\end{definition}
We rewrite \eqref{eq:y_operator} as
\begin{equation}
y_\nu(t) = \sum\limits_{\mu=1}^m \Phi_{c^{\mu\nu}}[w_\mu](t) 
\quad \forall \nu =1,2,\ldots , p   \label{eq:y_Phi}
\end{equation}
and discuss some properties.

\begin{lemma}{Properties of $\phi_k$}{}
	\begin{enumerate}
	\item $\phi_k[v](0) = 0$
	\item $\frac{\td}{\td t}\phi_0[v](t)=v(t)$ and
	$\frac{\td}{\td t}\phi_k[v](t) = \phi_{k-1}[v](t)$
%	\item $\phi_k$ is injective, i.e. $\phi_k[v]\equiv 0 \Rightarrow v\equiv 0$
	\end{enumerate}
\end{lemma}
\begin{proof}
	The first property is trivial.\\
	Computing $\phi_k[v](t+\Delta t)$ yields
	\begin{equation}
	\phi_k[v](t+\Delta t) = \int\limits_0^t \frac{(t-\tau + \Delta t)^k}{k!} v(\tau) 
	\, \td \tau + \int\limits_t^{t+\Delta t}   \frac{(t-\tau + \Delta t)^k}{k!} v(\tau) 
	\, \td \tau 
	\end{equation}
	and using $(t+\Delta t)^k =t^k + k t^{k-1} \Delta t + \mathcal{O}(\Delta t^2)$ for 
	$k>0$ and $(t+\Delta t)^0 = 1$ and a small $\Delta t$ leads to 
	\begin{equation}
	\phi_k[v](t+\Delta t) \simeq \int\limits_0^t \frac{(t-\tau)^k}{k!} v(t) \, \td \tau 
	+ \Delta t \int\limits_0^t \frac{(t-\tau)^{k-1}}{(k-1)!} v(t) \, \td \tau
	\end{equation}
	if $k>0$ and to 
	\begin{equation}
	\int\limits_0^t \frac{(t-\tau)^0}{k!} v(t) \, \td \tau +  \Delta t v(t)
	\end{equation}
	if $k=0$. Comparing this with the definitions of the operators we get \\
	$\phi_k[v](t+\Delta t) \simeq \phi_k(t) + \Delta t\phi_{k-1}[v](t)$ and 
	$\phi_0[v](t+\Delta t) \simeq \phi_0[v](t) + \Delta t v(t)$. Taking the limit 
	$\Delta t\to 0$ ends the proof of the derivation rules. \\
%	Setting $\phi_0[v]\equiv 0$ and taking the derivative $v\equiv 0$ shows, that 
%	$\phi_0$ is injective.
%	Assuming $\phi_{k-1}$ is injective, we set $\phi_k[v]\equiv 0$. Then also the 
%	derivative \\
%	$\frac{\td }{\td t}\phi_k[v]=\phi_{k-1}[v]\equiv 0$ which implies $v\equiv 0$ since 
%	$\phi_{k-1}$ is injective. This completes the induction.
\end{proof}

%\begin{lemma}{Unit Sequence}{}
%	If $c=(1,1,\ldots)$ or any multiple of this, then $\Phi_c$ is injective.
%\end{lemma}
%\begin{proof}
%	Set $\Phi_c[v]=\sum_{k=0}^\infty \phi_k[v] \equiv 0$. Derivation with respect to 
%	$t$ yields \\$v + \sum_{k=1}^\infty \phi_{k-1}[v]\equiv 0$ and shifting the index 
%	$k\to k-1$ shows\\ $v + \sum_{k=0}^\infty \phi_k[v]=v+\Phi_c[v]=v\equiv 0$.
%\end{proof}
\subsection{SISO-System}
We start with a \textit{Single Input Single Output (SISO)}-system. That means
\eqref{eq:y_Phi} simplifies to
\begin{equation}
	y(t) = \Phi_c[v](t)
\end{equation}
with a real-valued $y$ and $v$ and a scalar $c_k=(CA^kD)$.
\begin{proposition}{}{}
	Let $v$ be an integrable function on $[0^-,T^+]$ and let \\
	$\Phi_c[v]\equiv 0$. Then
	\begin{equation}
	\sum\limits_{l=0}^q c_l v^{(q-l)}(0)=0 \quad \forall q \in \mathbb{N}_0 \tag{$\star$}
	\label{eq:prop1}
	\end{equation}
	where $v^{(q)}(0)$ denotes the $q$-th derivative of $v$ at $t=0$.
\end{proposition}
\begin{proof}
	Consider
	\begin{equation}
	\Phi_c[v] = c_0 \phi_0[v] + c_1 \phi_1[v] + \ldots + c_{q-1}\phi_{q-1}[v] + 
	c_q \phi_q[v] + c_{q+1} \phi_{q+1}[v] + \ldots 
	\end{equation}
	and the $(q+1)$-th derivative
	\begin{equation}
	\left( \frac{\td}{\td t} \right)^{q+1}\Phi_c[v] = c_0 v^{(q)} + c_1 v^{(q-1)} + 
	\ldots 	+ c_{q-1} v^{(1)} + c_q v^{(0)} + c_{q+1} \phi_0[v] + \ldots
	\end{equation}
	for short
	\begin{equation}
	\left( \frac{\td}{\td t} \right)^{q+1}\Phi_c[v] = \sum\limits_{l=0}^q c_l v^{(q-l)} 
	+\sum\limits_{l=0}^\infty c_{q+1+l} \phi_{l}[v] \quad . 
	\end{equation}
	Evaluating the latter expression at $t=0$ completes the proof.
\end{proof}

To illustrate the idea of the following lemma and theorem we write down some 
instances of \eqref{eq:prop1}: 
\begin{align*}
&q = 0& &c_0 v^{(0)} \\
&q = 1& &c_0 v^{(1)} &&+&&c_1 v^{(0)} \\
&q = 2& &c_0 v^{(2)} &&+&&c_1 v^{(1)} &&+&&c_2 v^{(0)} \\
&q = 3& &c_0 v^{(3)} &&+&&c_1 v^{(2)} &&+&&c_2 v^{(1)} && +&&c_3 v^{(0)}\\
&q = 4& &c_0 v^{(4)} &&+&&c_1 v^{(3)} &&+&&c_2 v^{(2)} && +&&c_3 v^{(1)} &&+&& c_4 
v^{(0)} \\ 
&\,\, \vdots && && \ddots && &&\ddots && &&\ddots && &&\ddots && &&\ddots 
\end{align*}
For a better readability each $v^{(q)}$ is understood to be evaluated at $t=0$. The 
structure of this triangle remains the same if $c_0=0$, i.e. the first column vanishes, 
and if $v^{(0)}=0$, i.e. the diagonal at the top vanishes. 

\begin{lemma}{Induction Step}{}
	Assume proposition 1 holds and let $c_K$ be the first nonzero coefficient. 
	If there is a $r\in\mathbb{N}_0$ with $v^{(0)}(0)=
	v^{(1)}(0)=\ldots= v^{(r-1)}(0)=0$ then $v^{(r)}(0)=0$. 
\end{lemma}
\begin{proof}
	Using \eqref{eq:prop1} with $q = r+K$ yields 
	\begin{equation}
	\sum\limits_{l=0}^{r+K} c_l v^{(r+K-l)}(0) = c_K v^{(r)}(0) = 0
	\end{equation}
	since all other terms of the sum vanish due to $c_l=0$ or $v^{(l)}=0$. This shows 
	that also $v^{(r)}(0)=0$.
\end{proof}

\begin{theorem}{}{}
	Let $v\in L^2([0,T])\cap C^\infty(0^-,0^+)$ and $c$ a sequence. Then
	\begin{equation}
	\Phi_c[v] \equiv 0\quad  \Rightarrow\quad v^{(q)}(0) = 0
	 \quad \forall q\in\mathbb{N}_0 \quad .
	\end{equation}
\end{theorem}
\begin{proof}
	Let $c_K$ be the first nonzero coefficient. Using \eqref{eq:prop1} with $q=K$ yields 
	\begin{equation}
	c_K v^{(0)} = 0 
	\end{equation}
	which shows that $v^{(0)}=0$. Using lemma 2 completes the inductive proof.
\end{proof}

\begin{corollary}{}{}
	If $v$ can be represented by its Taylor-expansion, then $\Phi_c[v]\equiv 0$ implies 
	$v\equiv 0$.\\
	
	If there is a disjoint union $[0^-,T^+] = I_1\dot{\cap} I_2 \dot{\cap}\ldots$ such 
	that 
	$v$ has a valid Taylor-expansion on each interval $I_j=(t_{j-1}^-,t_j^+)$, we can argue 
	that $v\equiv 0$ on $I_1$. This leads to $\phi_k[v](t_1)=0$ which allows us to get 
	a modification of \eqref{eq:prop1}, written out
	\begin{equation}
	\sum\limits_{l=0}^q c_l v^{(q-l)}(t_1) = 0 \quad \forall q \in \mathbb{N}_0 \quad .
	\end{equation}
	Formally this can again be handled as an inductive proof to show, that $v$ must 
	vanish on each interval.\\
	
	A SISO-system is HIO if and only if there is an $K\in\mathbb{N}_0$ such that   
	$CA^KD \neq 0$. 
\end{corollary}

\subsection{MIMO-Systems}
As equation \eqref{eq:y_Phi} shows, we usually do not have a simple $y(t)=\Phi_c[v](t)$ 
relation but a sum with different sequences $c^{\mu\nu}$ and functions $w_\mu$.
Such a system is called \textit{Multiple Inputs Multiple Outputs (MIMO)}-system.
Since summation and differentiation are linear operations, we directly get the following 
extension of proposition 1.
\begin{proposition}{}{}
	Let $w_\mu$ integrable on $[0^-,T^+]$ for $\mu=1,2,\ldots , m$ and let 
	$c^{\mu\nu}$ be sequences. For each $\nu=1,2,\ldots, p$
	\begin{equation}
	\sum\limits_{\mu=1}^m \Phi_{c^{\mu\nu}}[w_\mu] \equiv 0 \quad \Rightarrow \quad 
	\sum\limits_{\mu=1}^m\sum\limits_{l=0}^q c^{\mu\nu}_l w_\mu^{(q-l)}(0) = 0 \quad 
	\forall q \in \mathbb{N}_0 \tag{$\star\star$} \label{eq:prop2}
 	\end{equation}
\end{proposition}
\begin{proof}
	The proof works analogous to that of proposition 1.
\end{proof}

Whereas theorem 1 holds for any sequence $c$ and function $v$, proposition 2 allows 
cancellation of different functions $w_\mu$. We shortly demonstrate, that a fully 
observed system will always be hidden input observable.
Considering a fully observed system with possible hidden inputs on each state, i.e. 
$C=D=\mathbb{1}$ and $p=n=m$, we directly get $c_0^{\mu\nu}=\delta_{\mu\nu}$. 
Inserting this into 
\eqref{eq:prop2} with $q=0$ yields 
\begin{equation}
w_\nu^{(0)} = 0 \tab{for} \nu = 1,2,\ldots , n
\end{equation}
Following the idea of lemma 2 we proceed with an induction step to get
\begin{equation}
w_\nu^{(q)} = 0 \quad \forall q\in\mathbb{N}_0 \tab{for} \nu = 1,2,\ldots , n \quad .
\end{equation}
As argued in corollary 1, if we assume that each $w_\mu$ can be represented by a 
Taylor series, we know, that this system is hidden input observable. \\

\subsubsection{Directly Observed Hidden Inputs}
To generalize the idea of an fully observed system we find the following lemma in analogy 
to lemma 2.
\begin{lemma}{Induction Step}{}
	Assume proposition 2 holds and assume for an integer $K$ 
	that $CD=CAD=\ldots = CA^{K-1}D = 0$ and $CA^KD$ has rank $m$. If there is an $r\in
	\mathbb{N}$ such that $w_\mu^{(0)}(0)=\ldots =w_\mu^{(r-1)}(0)=0$ for all $\mu =
	1,2,\ldots , m$, then $w_\mu^{(r)}(0)=0$ for all $\mu$.
\end{lemma}
\begin{proof}
	Using \eqref{eq:prop2} with $q=r+K$ yields
	\begin{equation}
	\sum\limits_{\mu=1}^m c_K^{\mu\nu} w_\mu^{(r)}(0) = 0
	\end{equation}
	which is by definition of $c_K^{\mu\nu}$ equivalent to the linear equation 
	\begin{equation}
	CA^K D w^{(r)} (0) = 0
	\end{equation}
	where $w^{(r)}(0)$ is the vector $(w_1^{(r)}(0),\ldots,w_m^{(r)}(0))$. If and only if 
	$\rank{CA^KD} = m$ this implies $w^{(r)}(0)=0\in\mathbb{R}^m$.
\end{proof}

\begin{theorem}{Directly Observed Hidden Inputs}{}
	Let $w\in L^2([0,T])^{\otimes m}\cap C^\infty(0^-,0^+)^{\otimes m}$ and $(A,C,D)$ the 
	matrices of 
	\eqref{eq:y} and assume that $CA^KD$ is the first nonvanishing coefficient matrix.\\ If 
	$\rank{CA^KD} = m$, then
	\begin{equation}
	y \equiv 0 \quad \Rightarrow \quad w_\mu^{(q)}(0) = 0 \quad \forall q\in\mathbb{N}_0
	\quad .
\end{equation}	 
\end{theorem}
\begin{proof}
	Due to the assumptions we can use proposition 2. Equation \eqref{eq:prop2} with 
	$q = K$ yields
	\begin{equation}
	\sum\limits_{\mu=1}^m c_K^{\mu\nu} w_\mu^{(0)}(0) = 
	\sum\limits_{\mu=1}^m \left( CA^KD\right)_{\nu\mu} w_\mu^{(0)}(0)= 0 \quad \forall 
	\nu \in \{1,2,\ldots, p\}
	\end{equation}
	which implies $w_\mu^{(0)}(0)=0\forall \mu$, since $(CA^KD):\mathbb{R}^m
	\to\mathbb{R}^p$ is injective. This allows us to use lemma 3 as an induction step to 
	complete the proof.
\end{proof}

\subsubsection{Indirectly Observed Hidden Inputs}
In the following example you can see a composition of two HIO systems. Though it should 
again be HIO, we cannot prove this by using theorem 2.
\begin{example}{}{}
	Consider the obviously HIO system
	\begin{equation}
	A = 0 \tab{,} D = 1 \tab{,} C = 1 \quad .
	\end{equation}
	Furthermore consider the system
	\begin{equation}
	A = \begin{pmatrix}
	0 & 0 \\ 1 & 0
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	1 \\ 0
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	0 & 1
	\end{pmatrix}
	\end{equation}
 	which yields $CD = 0$ and $CAD=1$ and therefore is also HIO.
 	If we simply write these two systems into one system
	\begin{equation}
	A = \begin{pmatrix}
	0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 1 & 0
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	1  & 0\\ 0 & 1 \\ 0 & 0
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	1&0&0\\0 &0 & 1
	\end{pmatrix}
	\end{equation}
 	we get $\rank{CD}=1$ which means we cannot apply theorem 2 to prove HIO.
\end{example}

To get an extension of theorem 2 we need a new construct. 
\begin{definition}{}{}
	Consider $CA^kD$ and define an index set $\mathcal{I}^k$ for each $k\in\mathbb{N}_0$
	by 
	\begin{equation}
	\mu \in\{1,2,\ldots,m\} \tab{is element of} \mathcal{I}^k \quad \Leftrightarrow 
	\quad  (CA^kD)_{. \mu} \neq 0  \quad . 
\end{equation}		
	Here $(CA^kD)_{.\mu}$ denotes the $\mu$-th column. \\
	
	For a better readability $\mathcal{R}^k:= 
	\mathcal{I}^k\backslash (\mathcal{I}^{k-1}\cup \ldots \cup \mathcal{I}^0)$.\\

	The \textit{reduced matrices} $(CA^kD)^*$ are defined by
	\begin{equation}
	(CD)^* = \left[ CD_{.\mu} \right]_{\mu \in \mathcal{I}^0}
	\end{equation}
	and 
	\begin{equation}
	(CA^kD)^* = \left[ (CA^{k-1}D)^* \left[ CA^kD_{.\mu}  \right]_{\mu\in\mathcal{R}^k} 
	\right]	 \quad .
	\end{equation}
	The square brackets mean the composition of columns to a new matrix.
\end{definition}

\begin{example}{}{}
	Let us again consider the latter example.
	\begin{equation}
	CD = \begin{pmatrix}
	1 & 0 \\ 0 & 0
	\end{pmatrix}
	\tab{,} CAD = \begin{pmatrix}
	0 & 0 \\ 0 & 1
	\end{pmatrix} 
	\end{equation}
	We find $\mathcal{I}^0=\{1\}$ and $\mathcal{I}^1 =\{2\}$. The reduced matrices are
	\begin{equation}
	(CD)^* = \begin{pmatrix}
	1 \\ 0
	\end{pmatrix}
	\tab{,} 
	(CAD)^* = \begin{pmatrix}
	1 & 0 \\ 0 & 1
	\end{pmatrix}
	\end{equation}
	The first matrix contains only the nonzero columns of $CD$.
	The second matrix is the composition of $(CD)^*$ and the columns of $(CAD)$ with index 
	in $\mathcal{I}^1\backslash\mathcal{I}^0 =\{2\}$. In this example it is the composition 
	of the first column of $CD$ and the second column of $CAD$. \\
	We can see that both reduced matrices have full column rank and that the reduced 
	matrix of the highest power, $(CAD)^*$, has rank $m$. 
\end{example}

Using this construct we can generalize theorem 2.
\begin{theorem}{Indirectly Observed Hidden Inputs}{}
	Let $w:[0^-,T^+]\to \mathbb{R}^m$ be element of $L^2([0,T])^{\otimes m}\cap C^\infty 
	(0^-,0^+)^{\otimes m}$ and let $(A,C,D)$ be the matrices of a linear dynamic system 
	\eqref{eq:y}. \\
	If each reduced matrix $(CA^kD)^*$ is injective, i.e. has full column rank, and if 
	there is an integer $K$ such that $(CA^KD)^*$ has rank $m$, then
	\begin{equation}
	y\equiv 0 \quad \Rightarrow \quad w_\mu^{(q)} (0) = 0 \quad \forall q \in \mathbb{N}_0 
	\quad .
	\end{equation}
\end{theorem}
\begin{proof}
	Once more we prove by induction. Writing $w_\mu^{(q)}$ always means evaluated 
	at $t=0$. Let us set $y\equiv 0$.
	\begin{enumerate}
	\item	Proposition 2 with $q=0$ yields 
			\begin{equation}
			\sum\limits_{\mu=1}^m c_0^{\mu \nu} w_\mu^{(0)} = 0  \,\, \forall \nu 
			\tab{which implies}
			 \sum\limits_{\mu=1}^m w_\mu^{(0)} CD_{.\mu}  = 0 \quad .
			\end{equation}
			By definition of $\mathcal{I}^0$ we get
			\begin{equation}
			\sum\limits_{\mu\in\mathcal{I}^0} w_\mu^{(0)} (CD)_{.\mu} = 0 \quad .
			\end{equation}
			Since this is a linear combination of the columns of an injective matrix
			$(CD)^*$ we get
			\begin{equation}
			w_\mu^{(0)} = 0 \quad \forall \mu \in \mathcal{I}^0 \quad .
			\end{equation}
	\item	Before we do the induction step, let us use proposition 2 with $q=1$ to get
			\begin{equation}
			\sum\limits_{\mu \in \mathcal{I}^0} c_0^{\mu\nu} w_\mu^{(1)} + 
			\sum\limits_{\mu\in\mathcal{R}^1} c_1^{\mu\nu} w_\mu^{(0)} = 0 \quad \forall
			\nu \quad .
			\end{equation}
			Again written as a vector equation this is equivalent to
			\begin{equation}
			\sum\limits_{\mu \in \mathcal{I}^0} w_\mu^{(1)} (CD)_{.\mu} + 
			\sum\limits_{\mu\in\mathcal{R}^1}  w_\mu^{(0)} (CAD)_{.\mu} = 0  \quad .
			\end{equation}
			This again is a linear combination of columns of $(CAD)^*$. Since $(CAD)^*$ is 
			injective we get
			\begin{equation}
			w_\mu^{(0)} = 0 \quad \forall \mu \in \mathcal{I}^0\cup \mathcal{R}^1 
			\tab{and} w_\mu^{(1)} = 0 \quad \forall\mu \in \mathcal{I}^0	\quad .
			\end{equation}
			We note that $\mathcal{R}^i \cup \mathcal{I}^{i-1}\cup \ldots\cup 
			\mathcal{I}^0$ is 
			equal to $\mathcal{I}^i \cup \mathcal{I}^{i-1}\cup \ldots \cup \mathcal{I}^0$.
	\item Following the idea of step 2 we do the induction step:\\ Assume we have found an 
			integer $r$ such that
			\begin{align*}
			w_\mu^{(0)} &= 0 \,\,
			\forall \mu \in \bigcup\limits_{\rho =0}^r \mathcal{I}^\rho  \\
			w_\mu^{(1)} &= 0 \, \,
			\forall \mu \in \bigcup\limits_{\rho =0}^{r-1} \mathcal{I}^\rho 
			\\	
			&\vdots
			 \\
			w_\mu^{(r)} & = 0 \, \,
			\forall \mu \in  \mathcal{I}^0
			\end{align*}
			then use proposition 2 with $q=r+1$ to get for all $\nu$
			\begin{equation}
			\sum\limits_{\mu=1}^m c_0^{\mu\nu} w_\mu^{(r+1)} + 
			\sum\limits_{\mu \not\in\mathcal{I}^0} c_1^{\mu\nu} w_\mu^{(r)} + 
			\ldots + 
			\sum\limits_{\mu\not\in\mathcal{I}^0\cup\ldots\cup \mathcal{I}^{r}} 
			c_{r+1}^{\mu\nu} w_\mu^{(0)} = 0		\quad .	 
			\end{equation}
			As a vector equation we get
			\begin{equation}
			\sum\limits_{\mu=1}^m w_\mu^{(r+1)} (CD)_{.\mu} + 
			\sum\limits_{\mu\not\in\mathcal{I}^0} w_\mu^{(r)} (CAD)_{.\mu}+ 
			\ldots + 
			\sum\limits_{\mu\not\in\mathcal{I}^0\cup\ldots\cup \mathcal{I}^{r}} 
			w_\mu^{(0)} (CA^{r+1}D)_{.\mu} = 0		\quad .	 
			\end{equation}						
			We easily see that the combination $\mu\in\mathcal{I}^{\rho+1}$ and $\mu\not\in 
			\mathcal{I}^\rho\cup\ldots\cup \mathcal{I}^0$ is the same as $\mu\in
			\mathcal{R}^{q+1}$. Using the knowledge of zero columns we get
			\begin{equation}
			\sum\limits_{\mu\in\mathcal{I}^0}^m w_\mu^{(r+1)} (CD)_{.\mu} + 
			\sum\limits_{\mu\in\mathcal{R}^1} w_\mu^{(r)} (CAD)_{.\mu}+ 
			\ldots + 
			\sum\limits_{\mu\in\mathcal{R}^{r+1}} 
			w_\mu^{(0)} (CA^{r+1}D)_{.\mu} = 0		\quad .	 
			\end{equation}
			This is a linear combination of columns of $(CA^{r+1}D)^*$ which is injective. 
			Therefore
			\begin{align*}
			w_\mu^{(0)} &= 0 \,\,
			\forall \mu \in \bigcup\limits_{\rho =0}^{r+1} \mathcal{I}^\rho  \\
			w_\mu^{(1)} &= 0 \, \,
			\forall \mu \in \bigcup\limits_{\rho =0}^{r} \mathcal{I}^\rho 
			\\	
			&\vdots
			 \\
			w_\mu^{(r)} & = 0 \, \,
			\forall \mu \in  \bigcup\limits_{\rho =0}^{1} \mathcal{I}^\rho \\
			w_\mu^{(r+1)} & = 0 \, \,
			\forall \mu \in  \mathcal{I}^0 
			\end{align*}				
			This completes the induction.
	\item	Due to the induction we know that 
			\begin{equation}
			w_\mu^{(q)} = 0\quad \forall \mu \in \bigcup\limits_{\rho=0}^r \mathcal{I}^\rho
			\end{equation}
			for all $q\in \mathbb{N}_0$ and for all $r\in\mathbb{N}_0$.
			We finally show that we can find an integer $r$ such that the latter 
			expression holds for all $\mu\in\{1,2,\ldots,m\}$.
			\begin{enumerate}
			\item Since by assumption there is an integer $K$ such that $(CA^KD)^*$ has 
			column rank $m$, we know that
			\begin{equation}
			\forall \mu \in \{1,2,\ldots,m\} \quad  \exists \quad \rho(\mu) \leq K 
			\quad | \quad \mu\in 
			\mathcal{I}^{\rho(\mu)} \quad .
			\end{equation}
			If this was not true, $(CA^KD)^*$ would have less than $m$ columns and 
			therefore could not have rank $m$. \\
			\item As a consequence we know that 
			\begin{equation}			
			\{0,1,2,\ldots, K\} \supseteq \{\rho(1),
			\rho(2),\ldots,\rho(m)\} \quad ,
			\end{equation} 
			hence
			\begin{equation}
			\bigcup\limits_{\rho=0}^K \mathcal{I}^\rho = \{1,2,\ldots,m\} \quad .
			\end{equation}
			\end{enumerate}
	\end{enumerate}		
\end{proof}


We complete the MIMO-systems with the last corollary in analogy to the SISO-system.
\begin{corollary}{}{}
	If there are a disjoint unions $[0^-,T^+]=I^\mu_1\dot{\cap} I_2^\mu\dot{\cap}\ldots$ 
	such that each $w_\mu$ can be represented by its Taylor-expansion on 
	each interval $I_j^\mu=((t_{j-1}^\mu)^- ,(t_j^\mu)^+)$ and if theorem 2 or theorem 3 
	holds, then the MIMO-system is HIO. \\
	
	Theorem 2 is a special case of theorem 3: \\
	If $CD=\ldots=CA^{K-1}D=0$ and $CA^KD$ injective, this is equivalent to $\mathcal{I}^0=
	\ldots =
	\mathcal{I}^{K-1} =\{0\}$ and $\mathcal{I}^K=\{1,2,\ldots,m\}$ which means 
	$(CD)^*=\ldots=(CA^{K-1}D)^*=0$ and $(CA^KD)^*=CA^KD$. \\	
	
	To have any $(CA^kD)^*$ of rank $m$, we need $p\geq m$.
\end{corollary}

\subsubsection{Hidden Input Observality with Overlapping Kernels}
The sufficient conditions we have found can be checked by calculating the rank of 
matrices. There is one more extension of theorem 3 possible. For that we need a new 
formalism.
%\begin{definition}{}{}
%	We define matrices 
%	\begin{equation}
%	M_k := \begin{bmatrix} CD & CAD & \ldots & CA^kD \end{bmatrix} \quad .
%	\end{equation}
%	Furthermore we write 
%	\begin{equation}	
%	\mathcal{K}^k := \kernel{CA^kD}
%	\end{equation}
%	and 
%	\begin{equation}
%	\mathcal{K}^k_* := \mathcal{K}^k \cap \mathcal{K}^{k-1} \cap \ldots \cap \mathcal{K}^0
%	 = \mathcal{K}^k \cap \mathcal{K}^{k-1}_* \quad .
%	\end{equation}
%	We will also need
%	\begin{equation}
%	\mathcal{K}^* := \lim_{k\to\infty} \mathcal{K}^k_* \quad .  
%	\end{equation}
%	It is convenient to write
%	\begin{equation}
%	\mathcal{N}^k := \mathcal{K}^0_* \oplus \mathcal{K}^1_* \oplus \ldots \oplus
%	\mathcal{K}^k_*  
%	\end{equation}
%	and
%	\begin{equation}
%	W^{(q)} = \begin{bmatrix}
%	w^{(q)} \\ w^{(q-1)} \\ \vdots \\ w^{(0)} 
%	\end{bmatrix}\quad .
%	\end{equation}		
%\end{definition}
%\begin{remark}{}{}
%	\begin{enumerate}
%	\item In this formalism it is convenient to write proposition 2 as
%		\begin{equation}
%		M_q W^{(q)} = 0 \quad \forall q\in\mathbb{N}_0	 \quad .
%		\end{equation}
%	\end{enumerate}
%\end{remark}
%\begin{lemma}{Induction Step}{}
%	If proposition 2 holds
%	\begin{equation}
%	W^{(r)}(0) \in \mathcal{N}^r\quad\Rightarrow\quad W^{(r+1)}(0) \in \mathcal{N}^{r+1}
%	\quad .  
%	\end{equation}
%\end{lemma}
%\begin{proof}
%	$W^{(r)}$ evaluated at $t=0$ is understood. By the assumption we know that
%	\begin{equation}
%	w^{(r)} \in \mathcal{K}^0_* \tab{,} w^{(r-1)} \in \mathcal{K}^1_* \tab{,} \ldots
%	\tab{,} w^{(0)} \in \mathcal{K}^r_* \quad .
%	\end{equation}
%	By proposition 2 we also know $W^{(r+1)} \in \kernel{M_{r+1}} $, that is
%	\begin{equation}
%	w^{(r+1)} \in \mathcal{K}^0 \tab{,} w^{(r)} \in \mathcal{K}^1 \tab{,} 
%	w^{(r-1)} \in \mathcal{K}^2 \tab{,} \ldots
%	\tab{,} w^{(0)} \in \mathcal{K}^{r+1} \quad .
%	\end{equation}
%	For every $q<r$ that means $w^{(q)}\in\mathcal{K}^k\cap \mathcal{K}^{k-1}_* = 
%	\mathcal{K}^k_*$. Also $w^{(r+1)}\in\mathcal{K}^0=\mathcal{K}^0_*$. So we found
%	\begin{equation}
%	\left( w^{(r+1)}, w^{(r)},\ldots,w^{(0)}\right) \in \mathcal{K}^0_* \oplus
%	 \mathcal{K}^1_* 
%	\oplus \ldots \oplus \mathcal{K}^{r+1}_* \tab{i.e}
%	W^{(r+1)} \in \mathcal{N}^{r+1} \quad .
%	\end{equation}
%\end{proof}
%
%\begin{theorem}{Overlapping Kernels}{}
%	Let $w:[0^-,T^+]\to \mathbb{R}^m$ be functions as before and $(A,C,D)$ the matrices 
%	of a linear dynamic system \eqref{eq:y}.
%	\begin{equation}
%	y\equiv 0 \quad \Rightarrow \quad w^{(q)}(0) \in \mathcal{K}^* \quad \forall q\in 
%	\mathbb{N}_0 \quad .
%	\end{equation}
%\end{theorem}
%\begin{proof}
%	As always we prove by induction and evaluate $W^{(q)}$ at $t=0$.
%	\begin{enumerate}
%	\item We can use proposition 2 with $q=0$ to get
%		\begin{equation}
%		M_0 W^{(0)} = 0 \quad \Rightarrow \quad W^{(0)}\in\kernel{M_0} = \mathcal{K}^0_*
%		= \mathcal{N}^0 \quad .
%		\end{equation}
%	\item Lemma 4 carries the induction step out.
%	\item That means for any integer $q$ we get 
%		\begin{equation}
%		w^{(q)} \in \mathcal{K}^k_* \quad \forall k\in\mathbb{N}_0
%		\end{equation}		  
%		which exactly means $w^{(q)}\in\mathcal{K}^*$.
%	\end{enumerate}
%\end{proof}

\begin{definition}{}{}
	We write
	\begin{align*}
	M_k &:= \begin{bmatrix} CD & CAD & \ldots & CA^kD \end{bmatrix} \\
	V_k &:= \kernel{M_k} \quad .
	\end{align*}
	We note that $M_k:\mathbb{R}^{(k+1)m} \to \mathbb{R}^p$ and $V_k\subseteq 
	\mathbb{R}^{(k+1)m}$. We define an inverse 
	projection $P$ that maps a (sub)vectorspace $V$ of $\mathbb{R}^{(k+1)m}$ to 
	$\mathbb{R}^{(k+2)m}$ by
	\begin{equation}
	P V = \left\{ \left. \begin{pmatrix}
	v \\ \hat{v}
	\end{pmatrix}
	\right| v\in\mathbb{R}^m \tab{and} \hat{v}\in V \right\} \quad .
	\end{equation}
	Furthermore we write
	\begin{equation}
	\Delta_k = V_k \cap P\Delta_{k-1} \tab{,} \Delta_0 = V_0
	\end{equation}
	and
	\begin{equation}
	W^{(q)} = \begin{bmatrix}
	w^{(q)} \\ w^{(q-1)} \\ \vdots \\ w^{(0)} 
	\end{bmatrix} \tab{,}
	W^{(q,r)} = \begin{bmatrix}
	w^{(q)} \\ w^{(q-1)} \\ \vdots \\ w^{(r)} 
	\end{bmatrix} \quad .
	\end{equation}
\end{definition}
\begin{lemma}{}{}
	\begin{enumerate}
	\item $W^{(q)} = [w^{(q)},W^{(q-1)}]^\text{T}$.
	\item It is convenient to rewrite proposition 2 in terms of the new definitions as
		\begin{equation}
		M_q W^{(q)} = 0 \quad \forall q\in\mathbb{N}_0	 \quad .
		\end{equation}
	\item If proposition 2 holds 
		\begin{equation}
		y \equiv 0 \Rightarrow W^{(0)} \in \Delta_0  \quad .
		\end{equation}
	\item If proposition 2 holds and $W^{(q)} \in \Delta_q$ then 
	$W^{(q+1)} \in \Delta_{q+1}$. 
	\end{enumerate}
\end{lemma}
\begin{proof}
	The first and second proof is just re-inserting the definitions.\\
	Using proposition with $q=0$ yields
	\begin{equation}
	M_0 W^{(0)} = 0 \quad \Rightarrow \quad W^{(0)} \in V_0 = \Delta_0 \quad . 
	\end{equation}\\
	Now assume $W^{(r)}\in\Delta_r$. Proposition 2 with $q=r+1$ yields
	\begin{equation}
	M_{r+1} W^{(r+1)} = 0 \quad \Rightarrow \quad W^{(r+1)} \in V_{r+1} \quad .
	\end{equation}
	That means 
	\begin{equation}	
	W^{(r+1)}=\left[w^{(q+1)},W^{(q)}\right] 
	\in V_{r+1} \cap (\mathbb{R}^m \times \Delta_r)
	= V_{r+1} \cap P\Delta_r = \Delta_{r+1} \quad .
	\end{equation}
\end{proof}
\begin{theorem}{}{}
	As a trivial consequence of lemma 4 but in analogy to the previous theorems
	\begin{equation}
	y\equiv 0 \quad \Rightarrow\quad W^{(q)}(0) \in \Delta_q \quad \forall q\in\mathbb{N}_0
	\quad .
	\end{equation}
	If for an integer $K$ we find $\Delta_K=\{0\}$, then $w^{(q)}(0)=0$ for all $q
	\in\mathbb{N}_0$. 
\end{theorem}
\begin{proof}
	The first implication is trivial using lemma 4. \\
	\begin{enumerate}
	\item 
		Assume we found such an integer $(K-1)$, then 
		\begin{equation}
		W^{(K-1)} \in \Delta_{K-1} \quad \Rightarrow \quad W^{(K-1)}=0
		\end{equation}
		is obvious. Now using proposition 2 with $q=r+K$ yields
		\begin{equation}
		M_{r+K} W^{(r+K)} = M_{r} W^{(r+K,K)} = 0\quad \forall r\in\mathbb{N}_0
		\end{equation}
		since all other terms will vanish. In complete analogy to what we found before
		\begin{equation}
		W^{(r+K,K)} \in \Delta_r \quad \forall r\in\mathbb{N}_0 \quad .
		\end{equation}
		Again setting $r=K-1$ we found $W^{(2K-1,K)}=0$ thus we can summarize
		\begin{equation}
		W^{(2K-1)} = 0 \quad .
		\end{equation}
	\item Assume $W^{(NK-1)}=0$ for some integer $N$. Choosing $q=r+NK$ in
		proposition 2 yields
		\begin{equation}
		M_r W^{(r+NK,NK)} = 0 \quad \forall r \in \mathbb{N}_0 \quad \Rightarrow \quad 
		 W^{(r+NK,NK)} \in \Delta_r \forall r\in \mathbb{N}_0
		\end{equation}
		and setting $r=K-1$ to get $W^{((N+1)K -1,NK)}=0$ and $W^{(N+1)K-1}=0$ completes 
		the inductive proof.
	\item Obviously $W^{(q)}=0$ for all $q\in\mathbb{N}_0$ implies $w^{(q)}=0$ for all $q$.
	\end{enumerate}
\end{proof}


\begin{corollary}{}{}
	In analogy to corollary 2, if all $w_\mu$ can be expressed by their Taylor-expansion, 
	the latter theorem is sufficient to prove HIO. \\
	
	Theorem 4 is an extension of theorem 3. We write $e_\mu$ for the vector with $1$ at 
	place $\mu$ and $0$ everywhere else. We find $\Delta_0=\text{span}\{e_\mu\}$ for $\mu$ 
	not in $\mathcal{I}^0$. Due to the condition that all reduced matrices are injective 
	we get $\Delta_1 =\text{span} \{e_\mu\}$ for $\mu$ not in $\mathcal{I}^1\cup 
	\mathcal{I}^0$ and so on. We already saw, that as $k$ increases, the union of 
	$\mathcal{I}^k$ reaches the 
	largest possible set $\{1,2,\ldots,m\}$ and therefore $\Delta_k$ reaches the smallest 
	possible vector space $\{0\}$.
\end{corollary}


\clearpage
\subsection{Hidden Input Observability Theorems}
Yet we found four theorems to proof a sufficient condition for HIO. Indeed, using the 
formalism of overlapping kernels we find the following necessary and sufficient conditions.
\begin{theorem}{Hidden Input Observability}{}
	Consider a linear dynamic system over an interval of time $[0^-,T^+]$
	\begin{equation*}
	\dot{x} = Ax + Bu + Dw  \tab{,}
	y=Cx \tab{,}
	x(0) = x_0 
	\end{equation*}
	with hidden inputs $w:[0^-,T^+]\to \mathbb{R}^m$. \\
	We restrict $w$ to be differentiable on subintervals of $[0^-,T^+]$ with a 
	Taylor-expansion that converges to $w$. 
	\begin{enumerate}
	\item
	The system is hidden input observable, if and only if there is an integer $K$ such that 
	$\Delta_K=\{0\}$.
	\item
	If for each $k\in\mathbb{N}_0$ the reduced matrix $(CA^kD)^*$ is injective,
	the system is hidden input observable if and only if
	there is an integer $K$ such that $(CA^KD)^*$ has rank $m$. 
	\end{enumerate}
\end{theorem}
\begin{proof}
	
	The sufficiency of this theorem is provided by theorem 4 and theorem 3, 
	respectively.
	\begin{enumerate}
	\item Assume there is no such integer $K$. We define $\Delta=\lim_{k\to\infty}$ which 
	is a nonempty subset of an infinite dimensional Hilbert space.\\
	 Choosing $W\in\Delta$ we get
		\begin{equation}
		W = \begin{bmatrix}
		\vdots \\ w^{(2)} \\w^{(1)} \\ w^{(0)}
		\end{bmatrix}
		\end{equation}
		Now we find
		\begin{equation}
		w(t) = \sum\limits_{k=0}^\infty \frac{t^k}{k!} w^{(k)}
		\end{equation}
		is a nontrivial hidden input that is mapped to $y\equiv 0$.
	
	\item We start with the second condition. Assume there is no integer $K$ that produces 
		$\rank{(CA^KD)^*}=m$. That means there is at least one $\mu'\in\{1,2,\ldots,m\}$ 
		with 
		\begin{equation}
		(CA^kD)_{.\mu'} = 0 \quad \forall k\in\mathbb{N}_0 \quad .
		\end{equation}			
		Without loss of generality say $m'=m$. This means 
		\begin{equation}		
		c_k^{m \nu}=0 \quad \forall k\in\mathbb{N}_0 \tab{and} \forall \nu\in\{1,2,
		\ldots,p\} \quad .
		\end{equation}
		We remember
		\begin{equation}
		y_\nu = \sum\limits_{\mu = 1}^m \Phi_{c^{\mu\nu}}[w_\mu] = 
		 \sum\limits_{\mu = 1}^m \sum\limits_{k=0}^\infty c_k^{\mu\nu}\phi_k[w_\mu]
		\end{equation}
		and since the latter equation holds for all $\nu$,
		\begin{equation}
		y_\nu = \sum\limits_{\mu = 1}^{m-1} \sum\limits_{k=0}^\infty c_k^{\mu\nu}\phi_k[w_
		\mu] \quad .
		\end{equation}
		This shows that $w_m$ has completely no influence on $y$ and therefore can be 
		chosen arbitrarily, which means the system is surely not HIO.	 
	\end{enumerate}
\end{proof}

\clearpage
\subsection{Examples}

\begin{example}{}{}
	\begin{equation}
	A = \begin{pmatrix}
	1 & 0 \\ 1 & 1
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	1 \\ 0
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	1 & 0
	\end{pmatrix}
	\end{equation}
	A SISO-system and $CAD=1$ thus it is HIO.
\end{example}
\begin{example}{}{}
	\begin{equation}
	A = \begin{pmatrix}
	1 & 0 \\ 1 & 1
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	0 \\ 1
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	1 & 0
	\end{pmatrix}
	\end{equation}
	A SISO-system and $CA^kD=0$ for any integer $k$ thus it is not HIO.
\end{example}
\begin{example}{}{}
	\begin{equation}
	A = \begin{pmatrix}
	0 & 0  & 1\\ 1 & 0 & 0 \\ 0 & 1 & 0
	\end{pmatrix}
	\quad
	D = \begin{pmatrix}
	1  & 0\\ 0 & 1 \\ 0 & 0
	\end{pmatrix}
	\quad 
	C = \begin{pmatrix}
	1 & 0 & 0 \\ 0 & 1 & 0
	\end{pmatrix}
	\end{equation}
	A MIMO-system and $CD$ is the $2\times 2$ identity matrix. Thus it is HIO.
\end{example}
